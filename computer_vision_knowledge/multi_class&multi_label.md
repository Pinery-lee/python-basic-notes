# å¤šç±»åˆ« (multi-class) VS. å¤šæ ‡ç­¾ (multi-label)

## 0. é—®é¢˜èƒŒæ™¯

æˆ‘åœ¨æŸ¥çœ‹ pytorch çš„å®˜æ–¹æ–‡æ¡£å…³äº [BCEWithLogitsLoss â€” PyTorch 2.6 documentation](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) çš„æ—¶å€™ï¼Œå‘ç°å®ƒç»™çš„ä¾‹å­å¦‚ä¸‹ï¼š

```python
target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10
output = torch.full([10, 64], 1.5)  # A prediction (logit)
pos_weight = torch.ones([64])  # All weights are equal to 1
criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)
criterion(output, target)  # -log(sigmoid(1.5))
```

æˆ‘å½“æ—¶çš„ç–‘æƒ‘å°±æ˜¯ä¸ºä»€ä¹ˆ target æ˜¯64ç±»ï¼Œ ä½†å´å¯ä»¥ç”¨äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°`BCEWithLogitsLoss`å‘¢ï¼ŸåŸå› åœ¨äºæˆ‘æ··æ·†äº†å¤šç±»åˆ«å’Œå¤šæ ‡ç­¾çš„åŒºåˆ«

------

## ğŸ§© 1. å››ç§åˆ†ç±»ä»»åŠ¡å…¨æ™¯å›¾

| ç±»å‹                 | è¯´æ˜                     | æ ‡ç­¾                                    | æ¨¡å‹è¾“å‡º                       | æŸå¤±å‡½æ•°                                  |
| -------------------- | ------------------------ | --------------------------------------- | ------------------------------ | ----------------------------------------- |
| **äºŒåˆ†ç±»ï¼ˆå•æ ‡ç­¾ï¼‰** | åªæœ‰ä¸¤ç±»ï¼Œäº’æ–¥           | `[0]` / `[1]`                           | `[B]`ï¼ˆ1ä¸ª logitï¼‰ æˆ– `[B, 2]` | `BCEWithLogitsLoss` or `CrossEntropyLoss` |
| **å¤šåˆ†ç±»ï¼ˆå•æ ‡ç­¾ï¼‰** | å¤šä¸ªç±»ï¼Œäº’æ–¥             | `[0, 2, 1]`                             | `[B, C]` logits                | `CrossEntropyLoss`                        |
| **å¤šæ ‡ç­¾äºŒåˆ†ç±»**     | æ¯ä¸ªæ ·æœ¬å¯æœ‰å¤šä¸ªæ ‡ç­¾     | `[0,1,0,1,...]` (one-hot å¤šç»´)          | `[B, C]` logits                | `BCEWithLogitsLoss`                       |
| **å¤šæ ‡ç­¾å¤šåˆ†ç±»**     | æ¯ä¸ªæ ‡ç­¾æœ¬èº«æ˜¯ä¸€ä¸ªå¤šåˆ†ç±» | å¤æ‚ç»“æ„ï¼Œä¾‹å¦‚ `[class1: 2, class2: 0]` | å¤šå¤´è¾“å‡º `[B, C1], [B, C2]...` | å¤šä¸ª `CrossEntropyLoss`                   |

------

## ğŸ§ 2. åˆ¤æ–­æ ‡å‡† & ç¤ºä¾‹

### âœ… 1. **äºŒåˆ†ç±»ï¼ˆå•æ ‡ç­¾ï¼‰**

- è¾“å‡ºï¼š`[B]` æˆ– `[B, 1]` logitï¼ˆåªé¢„æµ‹æ­£ç±»å¾—åˆ†ï¼‰
- æ ‡ç­¾ï¼š`[B]`ï¼Œ0 æˆ– 1
- æŸå¤±ï¼š`BCEWithLogitsLoss`

```python
output = model(x)           # shape: [B]
target = torch.tensor([0, 1, 1, 0])
loss = nn.BCEWithLogitsLoss()(output, target.float())
```

> ğŸ”¸ å¦‚æœç”¨äº† `[B, 2]` çš„è¾“å‡ºï¼ˆä¸¤ä¸ªç±»ï¼‰ï¼Œä¹Ÿå¯ä»¥ç”¨ `CrossEntropyLoss`ã€‚

------

### âœ… 2. **å¤šåˆ†ç±»ï¼ˆå•æ ‡ç­¾ï¼‰**

- æ¯ä¸ªæ ·æœ¬åªèƒ½å±äºä¸€ä¸ªç±»åˆ«
- è¾“å‡ºï¼š`[B, C]` logits
- æ ‡ç­¾ï¼š`[B]`ï¼Œæ•´æ•°ç±»åˆ«ç´¢å¼•
- æŸå¤±ï¼š`CrossEntropyLoss`

```python
output = model(x)           # shape: [B, C]
target = torch.tensor([0, 2, 1, 3])  # æ¯ä¸ªæ ·æœ¬å±äºå“ªä¸€ç±»
loss = nn.CrossEntropyLoss()(output, target)
```

------

### âœ… 3. **å¤šæ ‡ç­¾ï¼ˆäºŒåˆ†ç±»ï¼‰**

- æ¯ä¸ªæ ·æœ¬å¯èƒ½å±äºå¤šä¸ªç±»åˆ«
- è¾“å‡ºï¼š`[B, C]`ï¼Œæ¯ä¸ªç»´åº¦æ˜¯ä¸€ä¸ªç±»åˆ«
- æ ‡ç­¾ï¼š`[B, C]`ï¼Œ0/1 è¡¨ç¤ºè¯¥æ ‡ç­¾æ˜¯å¦å­˜åœ¨
- æŸå¤±ï¼š`BCEWithLogitsLoss`

```python
output = model(x)            # shape: [B, C]
target = torch.tensor([[1,0,1], [0,1,1]])  # æ¯ç±»æ˜¯å¦å‡ºç°
loss = nn.BCEWithLogitsLoss()(output, target.float())
```

------

### âœ… 4. **å¤šæ ‡ç­¾å¤šåˆ†ç±»**ï¼ˆè¾ƒå¤æ‚,ä¸€èˆ¬ä¸å¸¸ç”¨ï¼‰

- æ¯ç±»æ ‡ç­¾æ˜¯ä¸€ä¸ªå¤šåˆ†ç±»é—®é¢˜
- è¾“å‡ºå¤šä¸ª headsï¼Œæ¯ä¸ª head æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨
- æ ‡ç­¾æ˜¯å¤šä¸ªç±»åˆ«ç´¢å¼•ï¼Œå½¢å¦‚ï¼š`[batch, num_heads]`
- é€šå¸¸ç”¨å¤šä¸ª `CrossEntropyLoss` åˆå¹¶

```python
output1 = model_head1(x)    # shape: [B, C1]
output2 = model_head2(x)    # shape: [B, C2]
loss1 = nn.CrossEntropyLoss()(output1, target[:, 0])
loss2 = nn.CrossEntropyLoss()(output2, target[:, 1])
loss = loss1 + loss2
```

------

## ğŸ” 3. å¦‚ä½•è‡ªåŠ¨åˆ¤æ–­è¯¥ç”¨å“ªä¸ªæŸå¤±ï¼Ÿ

### ğŸ‘‡ å¯ä»¥é€šè¿‡æ ‡ç­¾ shape åˆ¤æ–­ï¼š

```python
if target.ndim == 1:
    loss_fn = nn.CrossEntropyLoss()  # å¤šåˆ†ç±»ï¼ˆå•æ ‡ç­¾ï¼‰
elif target.ndim == 2 and target.max() <= 1:
    loss_fn = nn.BCEWithLogitsLoss()  # å¤šæ ‡ç­¾ï¼ˆäºŒåˆ†ç±»ï¼‰
```

------

## ğŸ“ 4. æ€»ç»“ï¼šå¿«é€Ÿåˆ¤æ–­è¡¨

| ä»»åŠ¡         | æ ‡ç­¾ç±»å‹                | æ¨¡å‹è¾“å‡º      | æŸå¤±å‡½æ•°                |
| ------------ | ----------------------- | ------------- | ----------------------- |
| äºŒåˆ†ç±»       | `[0,1]`                 | `[B]`         | `BCEWithLogitsLoss`     |
| å¤šåˆ†ç±»       | `[0,1,2,...]`           | `[B, C]`      | `CrossEntropyLoss`      |
| å¤šæ ‡ç­¾åˆ†ç±»   | `[[0,1,1,...]]`         | `[B, C]`      | `BCEWithLogitsLoss`     |
| å¤šæ ‡ç­¾å¤šåˆ†ç±» | `[class1, class2, ...]` | å¤šä¸ª `[B, C]` | å¤šä¸ª `CrossEntropyLoss` |

------

æ›´å‡†ç¡®å’Œæ·±å…¥çš„æ¢è®¨å¯æŸ¥çœ‹[Multiclass Classification vs Multi-label Classification | GeeksforGeeks](https://www.geeksforgeeks.org/multiclass-classification-vs-multi-label-classification/)


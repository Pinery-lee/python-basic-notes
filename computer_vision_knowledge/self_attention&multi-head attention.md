# Self-attention 和 Multi-head Attention

## 0. 问题背景

随着计算机视觉中transformer模型所占的比例越来越高，以及火热的多模态模型，基于transformer的视觉模型与基于cnn的模型呈现分庭抗礼的态势。所以从[Attention Is All You Need](https://yiyibooks.cn/yiyibooks/Attention_Is_All_You_Need/index.html)该文中学习自注意力机制和多头注意力机制成了cv从业者的基本功。该文使用自注意力和多头注意力的动机在于：传统基于RNN或者CNN的模型在学习远距离依赖时(大的卷积核或者更多层)计算代价较高，Transformer 通过 self-attention 将其降低为常数复杂度，但引入了平均模糊（因为 attention 实质上是一个**加权平均（weighted sum）**操作，可能会导致信息“模糊化”。如果 attention 把注意力分配得过于平均，重要的信息可能会被其他不相关位置“稀释”。）的问题，这一问题可以用 Multi-Head Attention 来缓解。

## 1. 自注意力

自注意力，又称为缩放点积注意力机制，是应用最广泛的的注意力机制。

> 动机：自注意力提出的动机是为了减轻或者消除自然语言处理中RNN模型的并行化和长程依赖问题。

对比：

| **特性**         | **自注意力 (Self-Attention)**    | **RNN**                        | **CNN**                      |
| ---------------- | -------------------------------- | ------------------------------ | ---------------------------- |
| **依赖关系建模** | 全局依赖（任意位置间直接交互）   | 局部依赖（仅历史信息逐步传递） | 局部依赖（固定窗口内交互）   |
| **并行化能力**   | 完全并行（矩阵运算）             | 序列依赖，难以并行             | 部分并行（窗口内可并行）     |
| **长程依赖处理** | 天然支持长程依赖（无衰减）       | 梯度消失/爆炸问题严重          | 需堆叠多层扩大感受野         |
| **计算复杂度**   | $ O(n^2)$ （序列长度 \(n\)）     | $ O(n) $ （时间步计算）        | $O(k \cdot n) $ （核大小k）  |
| **参数共享**     | 无位置参数共享（但多头共享权重） | 时间步共享权重                 | 空间位置共享卷积核           |
| **典型应用场景** | Transformer、BERT、GPT           | 语言模型、时间序列预测         | 图像分类、文本分类（1D卷积） |

### 1.1 理论公式


$$
\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$


-  $ (Q, K, V) $ 为查询Query、键Key、值Value矩阵， $ \sqrt{d_k} $ 为缩放因子。
-  $ (Q, K, V) $ 表示每个 token 的 Query“要关注什么”、Key“匹配什么”，和 Value“输出什么”，由于 $ (Q, K, V) $ **都是来自于输入**，所以叫**自注意力**机制
-  第一步通过**点积**计算注意力得分（attention score）：点积 $QK^T$ 就是计算 $ Q $ 和 $ K $ 的相似度。
-  第二步将注意力得分进行**缩放**和**归一化**：缩放就是除以 $ \sqrt{d_k} $ , 归一化就是使用 $softmax$ ，得到注意力权重（attention weight)。这也是缩放点积注意力名称的来源。
-  第三步使用注意力权重对 $V$ 进行加权，得到输出。

### 1.2 为什么需要QKV?

**我们需要 QKV（Query、Key、Value）机制，而不是直接学习注意力权重，是为了让注意力具有**：
 ✅ 可泛化性、✅ 动态性、✅ 计算效率高、✅ 支持长序列、✅ 参数量小。

####  1.2.1 如果**直接学习注意力权重**会怎么样？

- 这意味着你要**为每个 token 学一个权重值**
- 权重是固定的，跟输入内容无关
- 对不同输入样本只能使用**同一套注意力连接** → 不能泛化
- 参数量巨大，不支持变化长度的序列
- 这本质上是：一个 **超大的全连接层或卷积核**

####  1.2.2 使用 QKV 的自注意力是怎么做的？

核心思路： $ Q = XW_q^T+B, K = XW_k^T+B, V = XW_v^T+B $  → QKV 是从输入通过线性变换动态生成的！

```python
self.query = nn.Linear(self.hidden_size, self.all_head_size, bias=config.qkv_bias)
self.key = nn.Linear(self.hidden_size, self.all_head_size, bias=config.qkv_bias)
self.value = nn.Linear(self.hidden_size, self.all_head_size, bias=config.qkv_bias)
```

> ✅ **在训练中，模型真正学习的参数是生成 Q、K、V 的权重矩阵** —— 即  $ W_q, W_k, W_v$ ，而不是注意力权重本身。注意力权重并不是直接学得的参数，而是通过输入计算出来的中间结果。

| 名称                | 参数性质   | 说明                                 |
| ------------------- | ---------- | ------------------------------------ |
| `W_Q`               | ✅ 可学习   | 把输入投影成 Query 空间              |
| `W_K`               | ✅ 可学习   | 把输入投影成 Key 空间                |
| `W_V`               | ✅ 可学习   | 把输入投影成 Value 空间              |
| `attention_weights` | ❌ 不是参数 | 是由 Q 和 K 计算出来的内容相关性结果 |

使用QKV计算注意力权重的好处：

| 特性             | QKV自注意力                       |
| ---------------- | --------------------------------- |
| **动态性**       | Q、K、V 是每个输入动态生成的      |
| **可泛化性**     | 同一套参数 W_q/k/v 可用于不同输入 |
| **参数量小**     | 只需学习 W_q/k/v（3 × d×d）       |
| **支持变长输入** | $QK^T$  自动适配不同序列长度      |
| **内容感知性**   | 不同输入产生不同注意力矩阵        |

#### 1.2.3 举例说明

假设你正在看一句话：“**The cat sat on the mat.**”

使用 QKV：

- 每个词（token）先生成一个 Query、Key、Value 向量
- Query 和所有 Key 点积，得到每个词对当前词的重要程度
- 再用这些权重加权 Value，得到当前词的语义表示

每次输入内容变了，Q、K、V 都变了，注意力权重也会跟着变。这是“**内容感知的连接权重**”。

#### 1.2.4 简要总结

| 问题                          | 回答简要说明                               |
| ----------------------------- | ------------------------------------------ |
| 为什么不用直接学习权重？      | 会固定、无法泛化、参数太多、输入不能变     |
| QKV 有什么用？                | 提供动态权重、支持变长输入、参数少、可泛化 |
| 是不是 QKV 最后也会变成权重？ | 是，但这些权重是**输入驱动、内容感知的**   |





[分析transformer模型的参数量、计算量、中间激活、KV cache - 知乎](https://zhuanlan.zhihu.com/p/624740065)
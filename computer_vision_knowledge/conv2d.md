# äºŒç»´å·ç§¯Conv2d

## 0. é—®é¢˜èƒŒæ™¯

ä½œä¸ºCNNæ¶æ„çš„æœ€æ ¸å¿ƒçš„æ¨¡å—ï¼Œå¿…é¡»è¦æŒæ¡å…¶ç†è®ºï¼Œå®ç°ï¼Œä½¿ç”¨å’Œä½¿ç”¨æ³¨æ„äº‹é¡¹ã€‚[Conv2d â€” PyTorch 2.6 documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)

## 1. ä»€ä¹ˆæ˜¯äºŒç»´å·ç§¯ï¼Ÿ

äºŒç»´å·ç§¯æ˜¯é€šè¿‡æ»‘åŠ¨ä¸€ä¸ªå°çš„å·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰åœ¨å›¾åƒä¸Šï¼Œå¯¹å±€éƒ¨åŒºåŸŸè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œä»è€Œæå–å›¾åƒçš„ç©ºé—´ç‰¹å¾çš„æ“ä½œã€‚

![åŠ¨å›¾](https://picx.zhimg.com/50/v2-15fea61b768f7561648dbea164fcb75f_720w.webp?source=1def8aca)

è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„äºŒç»´å·ç§¯ï¼Œç®€å•çš„ç‚¹åœ¨äºè¾“å…¥å›¾åƒçš„ç»´åº¦åªæœ‰1ç»´ï¼ˆè€Œä¸€èˆ¬æ˜¯RGBä¸‰ç»´ï¼‰ã€è¾“å‡ºçš„ç»´åº¦ä¹Ÿåªæœ‰ä¸€ç»´ï¼ˆé™¤äº†äºŒåˆ†ç±»çš„è¾“å‡ºå±‚ï¼Œä¸€èˆ¬ä¸ä¼šä¸º1ç»´ï¼‰ã€æ­¥é•¿ä¸º1,ã€å·ç§¯æ ¸å¤§å°åªæœ‰3*3ã€æ²¡æœ‰å¯¹åŸå›¾åƒåšpaddingã€æ²¡æœ‰æ·»åŠ åç½®ã€‚ä¸Šè¿°çš„torchå®ç°æ˜¯ï¼š

```python
import torch
import torch.nn as nn

# åˆ›å»ºè¾“å…¥
x = torch.tensor([[[[0,  0, 75, 80, 80],
                    [0, 75, 80, 80, 80],
                    [0, 75, 80, 80, 80],
                    [0, 70, 75, 80, 80],
                    [0,  0,  0,  0,  0]]]], dtype=torch.float32)

# åˆ›å»ºå·ç§¯å±‚
conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)

# æ‰‹åŠ¨è®¾ç½®æƒé‡ä¸ºå›¾ä¸­çš„æ ¸
kernel = torch.tensor([[[-1, -2, -1],
                        [ 0,  0,  0],
                        [ 1,  2,  1]]], dtype=torch.float32)

conv.weight.data = kernel.unsqueeze(0)  # shape [1, 1, 3, 3]

# æ‰§è¡Œå·ç§¯
output = conv(x)

print(output)
```

```python
tensor([[[[ 155.,   85.,    5.],
          [ -15.,  -15.,   -5.],
          [-230., -315., -320.]]]], grad_fn=<ConvolutionBackward0>)
```

## 2. `torch.nn.Conv2d`çš„å‚æ•°è§£é‡Š

### ğŸ“Œ æ„é€ å‡½æ•°åŸå‹ï¼š

```python
torch.nn.Conv2d(
    in_channels, 
    out_channels, 
    kernel_size, 
    stride=1, 
    padding=0, 
    dilation=1, 
    groups=1, 
    bias=True, 
    padding_mode='zeros'
)
```

------

### ğŸ“– å‚æ•°è§£é‡Šï¼š

- **in_channelsï¼ˆè¾“å…¥é€šé“æ•°ï¼‰**ï¼š
   ç±»å‹ï¼š`int`
   è¾“å…¥å›¾åƒçš„é€šé“æ•°ã€‚ä¾‹å¦‚ï¼ŒRGB å›¾ç‰‡æ˜¯ 3 é€šé“ï¼Œç°åº¦å›¾æ˜¯ 1 é€šé“ã€‚
   ğŸ‘‰ é€šå¸¸ç­‰äºå‰ä¸€å±‚çš„è¾“å‡ºé€šé“æ•°ã€‚
- **out_channelsï¼ˆè¾“å‡ºé€šé“æ•°ï¼‰**ï¼š
   ç±»å‹ï¼š`int`
   å·ç§¯ä¹‹åäº§ç”Ÿçš„é€šé“æ•°ï¼Œä¹Ÿå°±æ˜¯è¯¥å±‚å·ç§¯æ ¸çš„æ•°é‡ã€‚æ¯ä¸ªå·ç§¯æ ¸ä¼šç”Ÿæˆä¸€ä¸ªè¾“å‡ºé€šé“ã€‚
   ğŸ‘‰ è¿™ä¸ªå€¼å†³å®šäº†è¾“å‡ºç‰¹å¾å›¾çš„â€œåšåº¦â€ã€‚
- **kernel_sizeï¼ˆå·ç§¯æ ¸å¤§å°ï¼‰**ï¼š
   ç±»å‹ï¼š`int` æˆ– `tuple (height, width)`
   å·ç§¯æ ¸çš„å°ºå¯¸ã€‚ä¾‹å¦‚ `3` è¡¨ç¤º `3x3` çš„æ ¸ã€‚
   ğŸ‘‰ æ§åˆ¶æ„Ÿå—é‡çš„å¤§å°ã€‚
- **strideï¼ˆæ­¥é•¿ï¼‰**ï¼š
   ç±»å‹ï¼š`int` æˆ– `tuple`ï¼Œé»˜è®¤å€¼ä¸º `1`
   å·ç§¯æ ¸æ»‘åŠ¨çš„æ­¥é•¿ï¼Œå†³å®šè¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸ã€‚
   ğŸ‘‰ å¤§æ­¥é•¿ä¼šå‡å°è¾“å‡ºå°ºå¯¸ï¼ˆç±»ä¼¼ä¸‹é‡‡æ ·ï¼‰ã€‚
- **paddingï¼ˆå¡«å……ï¼‰**ï¼š
   ç±»å‹ï¼š`int`ã€`tuple` æˆ– `str`ï¼Œé»˜è®¤å€¼ä¸º `0`
   åœ¨è¾“å…¥å›¾åƒå››å‘¨æ·»åŠ çš„åƒç´ å±‚æ•°ã€‚
   ğŸ‘‰ é€šå¸¸ä½¿ç”¨ `padding=1` ä¿è¯è¾“å‡ºå°ºå¯¸ä¸è¾“å…¥ç›¸åŒï¼ˆåœ¨ stride=1 çš„æƒ…å†µä¸‹ï¼‰ã€‚
- **dilationï¼ˆç©ºæ´é•¿åº¦ï¼‰**ï¼š
   ç±»å‹ï¼š`int` æˆ– `tuple`ï¼Œ[1, H/W)ï¼Œé»˜è®¤å€¼ä¸º `1`
   æ§åˆ¶å·ç§¯æ ¸å†…éƒ¨å…ƒç´ ä¹‹é—´çš„é—´è·ã€‚1è¡¨ç¤ºå·ç§¯æ ¸ä¸­é—´ä¸æ’å…¥0ï¼Œnè¡¨ç¤ºåœ¨æ¯ä¸€è¡Œæˆ–åˆ—ä¸­é—´æ’å…¥**ï¼ˆdilation-1ï¼‰**ä¸ª0
   ğŸ‘‰ ç”¨äº **ç©ºæ´å·ç§¯**ï¼Œå¢å¤§æ„Ÿå—é‡è€Œä¸å¢åŠ å‚æ•°é‡ã€‚
- **groupsï¼ˆåˆ†ç»„å·ç§¯ï¼‰**ï¼š
   ç±»å‹ï¼š`int`ï¼Œé»˜è®¤å€¼ä¸º `1`
   æ§åˆ¶è¾“å…¥è¾“å‡ºä¹‹é—´çš„è¿æ¥æ–¹å¼ï¼š
  - `groups=1`ï¼šæ™®é€šå·ç§¯ï¼Œæ¯ä¸ªè¾“å…¥é€šé“è¿æ¥æ¯ä¸ªè¾“å‡ºé€šé“ï¼›
  - `groups=in_channels=out_channels`ï¼š**depthwise å·ç§¯**ï¼Œæ¯ä¸ªè¾“å…¥é€šé“ä½¿ç”¨ä¸€ä¸ªå·ç§¯æ ¸ç‹¬ç«‹å¤„ç†ï¼›
  - å…¶ä»–æƒ…å†µï¼š**åˆ†ç»„å·ç§¯**ï¼ˆå¦‚ ResNeXt ä¸­ä½¿ç”¨ï¼‰ã€‚
- **biasï¼ˆæ˜¯å¦æ·»åŠ åç½®é¡¹ï¼‰**ï¼š
   ç±»å‹ï¼š`bool`ï¼Œé»˜è®¤å€¼ä¸º `True`
   æ˜¯å¦ä¸ºæ¯ä¸ªè¾“å‡ºé€šé“æ·»åŠ ä¸€ä¸ªå¯å­¦ä¹ çš„åç½®é¡¹ã€‚
   ğŸ‘‰ å¦‚æœä½¿ç”¨äº† BatchNormï¼Œé€šå¸¸è®¾ç½®ä¸º `False`ã€‚
- **padding_modeï¼ˆå¡«å……æ–¹å¼ï¼‰**ï¼š
   ç±»å‹ï¼š`str`ï¼Œé»˜è®¤å€¼ä¸º `'zeros'`
   å¡«å……çš„æ¨¡å¼ï¼Œå¯é€‰å€¼æœ‰ï¼š
  - `'zeros'`ï¼šç”¨ 0 å¡«å……ï¼ˆé»˜è®¤ï¼‰
  - `'reflect'`ï¼šåå°„å¡«å……
  - `'replicate'`ï¼šå¤åˆ¶è¾¹ç•Œå€¼å¡«å……
  - `'circular'`ï¼šå¾ªç¯å¡«å……

## 3. è¾“å…¥è¾“å‡ºçš„å¼ é‡å½¢çŠ¶å˜åŒ–

- è¾“å…¥ï¼š**$\left(N, C_{i n}, H_{i n}, W_{i n}\right)$ æˆ–è€… $\left(C_{i n}, H_{i n}, W_{i n}\right)$**, æ³¨æ„æ˜¯é«˜HÃ—å®½W
- è¾“å‡ºï¼š$\left(N, C_{\text {out }}, H_{\text {out }}, W_{\text {out }}\right)$ æˆ–è€… $\left(C_{\text {out }}, H_{\text {out }}, W_{\text {out }}\right)$

$$
\begin{aligned}
& H_{\text {out }}=\left\lfloor\frac{H_{\text {in }}+2 \times \text { padding }[0]-\text { dilation }[0] \times(\text { kernel-size }[0]-1)-1}{\text { stride }[0]}+1\right\rfloor \\
& W_{\text {out }}=\left\lfloor\frac{W_{\text {in }}+2 \times \text { padding }[1]-\text { dilation }[1] \times(\text { kernel-size }[1]-1)-1}{\text { stride }[1]}+1\right\rfloor
\end{aligned}
$$

$H_{\text {in }}+2 \times \text { padding }$ æ˜¯å¡«å……ä¹‹åçš„åŸå›¾å¤§å°ï¼Œ$\text { dilation }\times(\text { kernel-size }-1)+1$ æ˜¯çœŸå®å·ç§¯æ ¸çš„å¤§å°ï¼Œ $H_{\text {in }}+2 \times \text { padding }-\text { dilation } \times(\text { kernel-size }-1)-1$ æ˜¯è¿™ä¸ªå·ç§¯æ ¸èƒ½æ»‘åŠ¨çš„èŒƒå›´ï¼Œæ‰€ä»¥å·ç§¯æ ¸èƒ½æ»‘åŠ¨çš„èŒƒå›´é™¤ä»¥æ­¥é•¿å°±æ˜¯è¾“å‡ºçš„ç»´åº¦ï¼Œä½†æ˜¯å¦‚æœä¸èƒ½æ•´é™¤ï¼Œ æœ€åå¤šä½™çš„å‡ è¡Œ/åˆ—ä¸å‚ä¸å·ç§¯ï¼æ‰€ä»¥è¦åŠ 1ç„¶åå‘ä¸‹å–æ•´ã€‚

å®éªŒï¼š

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6, dtype=torch.float32).reshape(1, 1, 6, 6)
print("è¾“å…¥ x:")
print(x[0, 0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=1,
    out_channels=1,
    kernel_size=3,
    stride=2,
    padding=1,
    bias=False
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0, 0])
```

```python
è¾“å…¥ x:
tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],
        [ 6.,  7.,  8.,  9., 10., 11.],
        [12., 13., 14., 15., 16., 17.],
        [18., 19., 20., 21., 22., 23.],
        [24., 25., 26., 27., 28., 29.],
        [30., 31., 32., 33., 34., 35.]])

è¾“å‡º shape: torch.Size([1, 1, 3, 3])
è¾“å‡ºç»“æœ:
tensor([[ 14.,  30.,  42.],
        [ 75., 126., 144.],
        [147., 234., 252.]], grad_fn=<SelectBackward0>)
```

###  è¾“å‡ºè§£é‡Š

- è¾“å…¥æ˜¯ `6Ã—6`ï¼Œstride=2ï¼Œpadding=1ï¼ŒåŸå›¾åƒå¤§å°å°±ä¼šå˜ä¸º6+2=8ï¼Œå·ç§¯æ ¸å¤§å°ä¸º3ï¼Œæ‰€æœ‰å·ç§¯æ ¸çš„æ»‘åŠ¨èŒƒå›´ä¸º5ï¼Œæ¯æ¬¡æ»‘åŠ¨2ï¼Œæ‰€ä»¥æœ€åä¸€è¡Œå·ç§¯ä¸åˆ°ï¼Œæœ€åä¸€è¡Œæ˜¯paddingè¡Œä¸º0
- æ ¹æ®è¾“å‡ºå…¬å¼ï¼š

$$
H_{\text{out}} = \left\lfloor \frac{H_{\text{in}} + 2 \times \text{padding} - (k - 1) - 1}{\text{stride}} + 1 \right\rfloor = \left\lfloor \frac{6 + 2 - 2 - 1}{2} + 1 \right\rfloor = \left\lfloor \frac{5}{2} + 1 \right\rfloor = 3
$$

- å¯¹äºç»“æœç¬¬ä¸€åˆ—è€Œè¨€ï¼Œ14å¯¹åº”0çš„ä½ç½®ï¼Œ1+6+7=14ï¼›75å¯¹åº”12çš„ä½ç½®ï¼Œ6+7+12+13+18+19=75ï¼›147å¯¹åº”24çš„ä½ç½®ï¼Œ18+19+24+25+30+31=147ï¼›æœ€åçš„é›¶è¡Œè¢«èˆå¼ƒä¸å‚ä¸å·ç§¯ã€‚

æ‰€ä»¥è¾“å‡ºçš„å½¢çŠ¶æ˜¯ **3Ã—3**

## 4. å·ç§¯å±‚çš„å˜é‡ Variables

- **weight**æƒé‡ï¼šå¯å­¦ä¹ çš„æƒé‡ï¼Œå…¶å®å°±æ˜¯æ‰€æœ‰çš„å·ç§¯æ ¸åˆå¹¶ä¸ºçš„ä¸€ä¸ªå¼ é‡ã€‚å½¢çŠ¶æ˜¯ ï¼ˆout_channels, in_channels/groups, kernel_size[0], kernel_size[1]ï¼‰ã€‚é»˜è®¤ä½¿ç”¨å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ã€‚
- **bias**åç½®ï¼šå¯å­¦ä¹ çš„åç½®ï¼Œå½¢çŠ¶æ˜¯ï¼ˆout_channelsï¼‰ï¼Œåˆå§‹åŒ–åŒä¸Šã€‚

## 5. groups å‚æ•°

å¦‚æœè®¾ç½®äº† `groups=g`ï¼Œé‚£ä¹ˆï¼š

- è¾“å…¥é€šé“è¢«åˆ†æˆ `g` ç»„ï¼Œæ¯ç»„å¤§å° = `in_channels // g`
- è¾“å‡ºé€šé“ä¹Ÿåˆ† `g` ç»„ï¼Œæ¯ç»„å¤§å° = `out_channels // g`
- æ¯ç»„å†…éƒ¨ç‹¬ç«‹å·ç§¯ï¼ˆä¸è·¨ç»„ï¼‰

æ‰€ä»¥`groups`çš„å–å€¼å¿…é¡»æ˜¯[1, max(in_channels, out_channels)], ä¸”å¿…é¡»èƒ½æ•´é™¤in_channelså’Œout_channels

## 6. å¸¸è§çš„ç‰¹æ®Šå½¢å¼

------

## âœ… 1. æ ‡å‡†å·ç§¯ï¼ˆStandard Convolutionï¼‰

- `groups=1`ï¼ˆé»˜è®¤å€¼ï¼‰
- æ¯ä¸ªè¾“å‡ºé€šé“è¿æ¥æ‰€æœ‰è¾“å…¥é€šé“

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 3, dtype=torch.float32).reshape(1, 3, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=3,
    out_channels=1,
    kernel_size=3,
    bias=False,
    padding=1
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],
         [  6.,   7.,   8.,   9.,  10.,  11.],
         [ 12.,  13.,  14.,  15.,  16.,  17.],
         [ 18.,  19.,  20.,  21.,  22.,  23.],
         [ 24.,  25.,  26.,  27.,  28.,  29.],
         [ 30.,  31.,  32.,  33.,  34.,  35.]],

        [[ 36.,  37.,  38.,  39.,  40.,  41.],
         [ 42.,  43.,  44.,  45.,  46.,  47.],
         [ 48.,  49.,  50.,  51.,  52.,  53.],
         [ 54.,  55.,  56.,  57.,  58.,  59.],
         [ 60.,  61.,  62.,  63.,  64.,  65.],
         [ 66.,  67.,  68.,  69.,  70.,  71.]],

        [[ 72.,  73.,  74.,  75.,  76.,  77.],
         [ 78.,  79.,  80.,  81.,  82.,  83.],
         [ 84.,  85.,  86.,  87.,  88.,  89.],
         [ 90.,  91.,  92.,  93.,  94.,  95.],
         [ 96.,  97.,  98.,  99., 100., 101.],
         [102., 103., 104., 105., 106., 107.]]])

è¾“å‡º shape: torch.Size([1, 1, 6, 6])
è¾“å‡ºç»“æœ:
tensor([[[ 474.,  720.,  738.,  756.,  774.,  522.],
         [ 765., 1161., 1188., 1215., 1242.,  837.],
         [ 873., 1323., 1350., 1377., 1404.,  945.],
         [ 981., 1485., 1512., 1539., 1566., 1053.],
         [1089., 1647., 1674., 1701., 1728., 1161.],
         [ 762., 1152., 1170., 1188., 1206.,  810.]]],
       grad_fn=<SelectBackward0>)
```

- 474=0+1+6+7+36+37+42+43+72+73+78+79

## âœ… 2.  æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Convolutionï¼‰

- `groups=in_channels`, out_channelså°†è‡³å°‘ä¸º1*groups
- æ¯ä¸ªè¾“å…¥é€šé“å¯¹åº”ä¸€ä¸ªå·ç§¯æ ¸ï¼Œ**ä¸æ··é€šé“**

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 3, dtype=torch.float32).reshape(1, 3, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=3,
    out_channels=3,
    kernel_size=3,
    bias=False,
    padding=1,
    groups=3
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],
         [  6.,   7.,   8.,   9.,  10.,  11.],
         [ 12.,  13.,  14.,  15.,  16.,  17.],
         [ 18.,  19.,  20.,  21.,  22.,  23.],
         [ 24.,  25.,  26.,  27.,  28.,  29.],
         [ 30.,  31.,  32.,  33.,  34.,  35.]],

        [[ 36.,  37.,  38.,  39.,  40.,  41.],
         [ 42.,  43.,  44.,  45.,  46.,  47.],
         [ 48.,  49.,  50.,  51.,  52.,  53.],
         [ 54.,  55.,  56.,  57.,  58.,  59.],
         [ 60.,  61.,  62.,  63.,  64.,  65.],
         [ 66.,  67.,  68.,  69.,  70.,  71.]],

        [[ 72.,  73.,  74.,  75.,  76.,  77.],
         [ 78.,  79.,  80.,  81.,  82.,  83.],
         [ 84.,  85.,  86.,  87.,  88.,  89.],
         [ 90.,  91.,  92.,  93.,  94.,  95.],
         [ 96.,  97.,  98.,  99., 100., 101.],
         [102., 103., 104., 105., 106., 107.]]])

è¾“å‡º shape: torch.Size([1, 3, 6, 6])
è¾“å‡ºç»“æœ:
tensor([[[ 14.,  24.,  30.,  36.,  42.,  30.],
         [ 39.,  63.,  72.,  81.,  90.,  63.],
         [ 75., 117., 126., 135., 144.,  99.],
         [111., 171., 180., 189., 198., 135.],
         [147., 225., 234., 243., 252., 171.],
         [110., 168., 174., 180., 186., 126.]],

        [[158., 240., 246., 252., 258., 174.],
         [255., 387., 396., 405., 414., 279.],
         [291., 441., 450., 459., 468., 315.],
         [327., 495., 504., 513., 522., 351.],
         [363., 549., 558., 567., 576., 387.],
         [254., 384., 390., 396., 402., 270.]],

        [[302., 456., 462., 468., 474., 318.],
         [471., 711., 720., 729., 738., 495.],
         [507., 765., 774., 783., 792., 531.],
         [543., 819., 828., 837., 846., 567.],
         [579., 873., 882., 891., 900., 603.],
         [398., 600., 606., 612., 618., 414.]]], grad_fn=<SelectBackward0>)
```

- 14 = 0+1+6+7; 158 = 36+37+42+43; 302 = 72+73+78+79

## âœ… 3.  åˆ†ç»„å·ç§¯ï¼ˆGroup Convolutionï¼‰

- `1 < groups < in_channels`
- æ¯”å¦‚ `groups=2`ï¼šæŠŠè¾“å…¥åˆ†æˆä¸¤ç»„ï¼Œæ¯ç»„ç”¨ç‹¬ç«‹å·ç§¯æ ¸å¤„ç†

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 4, dtype=torch.float32).reshape(1, 4, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=4,
    out_channels=2,
    kernel_size=3,
    bias=False,
    padding=1,
    groups=2
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],
         [  6.,   7.,   8.,   9.,  10.,  11.],
         [ 12.,  13.,  14.,  15.,  16.,  17.],
         [ 18.,  19.,  20.,  21.,  22.,  23.],
         [ 24.,  25.,  26.,  27.,  28.,  29.],
         [ 30.,  31.,  32.,  33.,  34.,  35.]],

        [[ 36.,  37.,  38.,  39.,  40.,  41.],
         [ 42.,  43.,  44.,  45.,  46.,  47.],
         [ 48.,  49.,  50.,  51.,  52.,  53.],
         [ 54.,  55.,  56.,  57.,  58.,  59.],
         [ 60.,  61.,  62.,  63.,  64.,  65.],
         [ 66.,  67.,  68.,  69.,  70.,  71.]],

        [[ 72.,  73.,  74.,  75.,  76.,  77.],
         [ 78.,  79.,  80.,  81.,  82.,  83.],
         [ 84.,  85.,  86.,  87.,  88.,  89.],
         [ 90.,  91.,  92.,  93.,  94.,  95.],
         [ 96.,  97.,  98.,  99., 100., 101.],
         [102., 103., 104., 105., 106., 107.]],

        [[108., 109., 110., 111., 112., 113.],
         [114., 115., 116., 117., 118., 119.],
         [120., 121., 122., 123., 124., 125.],
         [126., 127., 128., 129., 130., 131.],
         [132., 133., 134., 135., 136., 137.],
         [138., 139., 140., 141., 142., 143.]]])

è¾“å‡º shape: torch.Size([1, 2, 6, 6])
è¾“å‡ºç»“æœ:
tensor([[[ 172.,  264.,  276.,  288.,  300.,  204.],
         [ 294.,  450.,  468.,  486.,  504.,  342.],
         [ 366.,  558.,  576.,  594.,  612.,  414.],
         [ 438.,  666.,  684.,  702.,  720.,  486.],
         [ 510.,  774.,  792.,  810.,  828.,  558.],
         [ 364.,  552.,  564.,  576.,  588.,  396.]],

        [[ 748., 1128., 1140., 1152., 1164.,  780.],
         [1158., 1746., 1764., 1782., 1800., 1206.],
         [1230., 1854., 1872., 1890., 1908., 1278.],
         [1302., 1962., 1980., 1998., 2016., 1350.],
         [1374., 2070., 2088., 2106., 2124., 1422.],
         [ 940., 1416., 1428., 1440., 1452.,  972.]]],
       grad_fn=<SelectBackward0>)
```

- 172 = 0+1+6+7+36+37+42+43ï¼ˆç¬¬ä¸€ç»„ï¼‰; 748 = 72+73+78+79+108+109+114+115ï¼ˆç¬¬äºŒç»„ï¼‰

## âœ… 4. 1x1 å·ç§¯ï¼ˆPointwise Convolutionï¼‰

- `kernel_size=1`
- å¸¸ç”¨äº**é€šé“ç»´åº¦å‹ç¼©æˆ–æ‰©å±•**

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 3, dtype=torch.float32).reshape(1, 3, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=3,
    out_channels=1,
    kernel_size=1,
    bias=False,
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],
         [  6.,   7.,   8.,   9.,  10.,  11.],
         [ 12.,  13.,  14.,  15.,  16.,  17.],
         [ 18.,  19.,  20.,  21.,  22.,  23.],
         [ 24.,  25.,  26.,  27.,  28.,  29.],
         [ 30.,  31.,  32.,  33.,  34.,  35.]],

        [[ 36.,  37.,  38.,  39.,  40.,  41.],
         [ 42.,  43.,  44.,  45.,  46.,  47.],
         [ 48.,  49.,  50.,  51.,  52.,  53.],
         [ 54.,  55.,  56.,  57.,  58.,  59.],
         [ 60.,  61.,  62.,  63.,  64.,  65.],
         [ 66.,  67.,  68.,  69.,  70.,  71.]],

        [[ 72.,  73.,  74.,  75.,  76.,  77.],
         [ 78.,  79.,  80.,  81.,  82.,  83.],
         [ 84.,  85.,  86.,  87.,  88.,  89.],
         [ 90.,  91.,  92.,  93.,  94.,  95.],
         [ 96.,  97.,  98.,  99., 100., 101.],
         [102., 103., 104., 105., 106., 107.]]])

è¾“å‡º shape: torch.Size([1, 1, 6, 6])
è¾“å‡ºç»“æœ:
tensor([[[108., 111., 114., 117., 120., 123.],
         [126., 129., 132., 135., 138., 141.],
         [144., 147., 150., 153., 156., 159.],
         [162., 165., 168., 171., 174., 177.],
         [180., 183., 186., 189., 192., 195.],
         [198., 201., 204., 207., 210., 213.]]], grad_fn=<SelectBackward0>)
```

- 108 = 0+36+72

## âœ… 5. ç©ºæ´å·ç§¯ï¼ˆDilated Convolutionï¼‰

![åŠ¨å›¾](https://pica.zhimg.com/v2-9c531569460c694db396a7530d8e5ffc_b.webp)

- `dilation > 1`ï¼šæ‰©å¤§æ„Ÿå—é‡ï¼Œä¸åŠ å‚æ•°

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 3, dtype=torch.float32).reshape(1, 3, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=3,
    out_channels=1,
    kernel_size=3,
    bias=False,
    dilation=2
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],
         [  6.,   7.,   8.,   9.,  10.,  11.],
         [ 12.,  13.,  14.,  15.,  16.,  17.],
         [ 18.,  19.,  20.,  21.,  22.,  23.],
         [ 24.,  25.,  26.,  27.,  28.,  29.],
         [ 30.,  31.,  32.,  33.,  34.,  35.]],

        [[ 36.,  37.,  38.,  39.,  40.,  41.],
         [ 42.,  43.,  44.,  45.,  46.,  47.],
         [ 48.,  49.,  50.,  51.,  52.,  53.],
         [ 54.,  55.,  56.,  57.,  58.,  59.],
         [ 60.,  61.,  62.,  63.,  64.,  65.],
         [ 66.,  67.,  68.,  69.,  70.,  71.]],

        [[ 72.,  73.,  74.,  75.,  76.,  77.],
         [ 78.,  79.,  80.,  81.,  82.,  83.],
         [ 84.,  85.,  86.,  87.,  88.,  89.],
         [ 90.,  91.,  92.,  93.,  94.,  95.],
         [ 96.,  97.,  98.,  99., 100., 101.],
         [102., 103., 104., 105., 106., 107.]]])

è¾“å‡º shape: torch.Size([1, 1, 2, 2])
è¾“å‡ºç»“æœ:
tensor([[[1350., 1377.],
         [1512., 1539.]]], grad_fn=<SelectBackward0>)
```

- 1350 = 0+2+4+12+14+16+24+26+28 + 36+38+40+48+50+52+60+62+64 + 72+74+76+84+86+88+96+98+100

## âœ… 6. è·¨æ­¥å·ç§¯ï¼ˆStrided Convolutionï¼‰

[Strided Convolutions](https://www.baeldung.com/cs/neural-nets-strided-convolutions)

- èƒ½é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œé€šè¿‡è·³è¿‡åƒç´ ï¼Œç½‘ç»œå¯ä»¥æ›´é«˜æ•ˆåœ°å¤„ç†è¾ƒå¤§çš„å›¾åƒ
- ä¸‹é‡‡æ ·ç”¨ï¼Œæ•ˆæœç­‰ä»·äºå·ç§¯ + pooling

```python
import torch
import torch.nn as nn

# è¾“å…¥å¤§å°ï¼š6x6ï¼ˆä¸èƒ½è¢«stride=2æ•´é™¤ï¼‰
x = torch.arange(6 * 6 * 1, dtype=torch.float32).reshape(1, 1, 6, 6)
print("è¾“å…¥ x:")
print(x[0])

# å·ç§¯å‚æ•°
conv = nn.Conv2d(
    in_channels=1,
    out_channels=1,
    kernel_size=3,
    bias=False,
    stride=2
)

# æƒé‡å…¨è®¾ä¸º1ï¼Œæ–¹ä¾¿éªŒè¯æ±‚å’ŒåŒºåŸŸ
with torch.no_grad():
    conv.weight.fill_(1.0)

# æ‰§è¡Œå·ç§¯
output = conv(x)
print("\nè¾“å‡º shape:", output.shape)
print("è¾“å‡ºç»“æœ:")
print(output[0])
```

```python
è¾“å…¥ x:
tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],
         [ 6.,  7.,  8.,  9., 10., 11.],
         [12., 13., 14., 15., 16., 17.],
         [18., 19., 20., 21., 22., 23.],
         [24., 25., 26., 27., 28., 29.],
         [30., 31., 32., 33., 34., 35.]]])

è¾“å‡º shape: torch.Size([1, 1, 2, 2])
è¾“å‡ºç»“æœ:
tensor([[[ 63.,  81.],
         [171., 189.]]], grad_fn=<SelectBackward0>)
```

- 63 = 0+1+2+6+7+8+12+13+14ï¼›171 = 12+13+14+18+19+20+24+25+26ï¼›**æœ€åä¸€è¡Œä¸å‚ä¸å·ç§¯**

## ğŸ“Œ æ€»ç»“å¯¹æ¯”è¡¨

| ç±»å‹           | groups       | kernel_size | dilation | stride | åº”ç”¨åœºæ™¯              |
| -------------- | ------------ | ----------- | -------- | ------ | --------------------- |
| æ ‡å‡†å·ç§¯       | 1            | ä»»æ„        | 1        | 1      | å¸¸è§„å·ç§¯æ“ä½œ          |
| æ·±åº¦å¯åˆ†ç¦»å·ç§¯ | =in_channels | ä»»æ„        | 1        | 1      | MobileNet, è½»é‡æ¨¡å‹   |
| åˆ†ç»„å·ç§¯       | >1           | ä»»æ„        | 1        | 1      | ResNeXt, ç‰¹å¾åˆ†ç»„å¤„ç† |
| 1x1å·ç§¯        | 1            | 1           | 1        | 1      | é€šé“å˜æ¢ã€ç“¶é¢ˆç»“æ„    |
| ç©ºæ´å·ç§¯       | 1            | ä»»æ„        | >1       | 1      | è¯­ä¹‰åˆ†å‰²ï¼Œæ‰©å¤§æ„Ÿå—é‡  |
| è·¨æ­¥å·ç§¯       | 1            | ä»»æ„        | 1        | >1     | ä¸‹é‡‡æ ·ï¼Œæ›¿ä»£ pooling  |

